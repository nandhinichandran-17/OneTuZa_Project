# OneTuZa â€” Multi-Document Research Agent (RAG + Planning)

## Summary
This project implements a Research Assistant that:
- Accepts a natural language question.
- Searches local PDF/Markdown documents and the web (Wikipedia, optional SerpAPI).
- Retrieves top-k relevant chunks using dense-vector retrieval (FAISS + SentenceTransformers).
- Synthesizes a structured Markdown report with inline citations and traceability.
- Implements a planner â†’ retriever â†’ synthesizer multi-step pipeline.

## Repo structure
one-tuza-rag/
â”œâ”€ README.md
â”œâ”€ ingest.py
â”œâ”€ vectorstore.py
â”œâ”€ web_search.py
â”œâ”€ planner.py
â”œâ”€ synthesizer.py
â”œâ”€ app.py
â”œâ”€ docs/

## Quick start

1.Clone:
```bash
git clone <your_repo_url>
cd one-tuza-rag

2.Create .env from .env.example and add keys if using OpenAI/SerpAPI.

3.Install:
pip install -r requirements.txt

4.Add local docs (PDF/MD/TXT) to docs/.

5.Run:
 streamlit run app.py
 
6.	In the UI:
	â€¢	click â€œ(Re)build index nowâ€
	â€¢	enter question
	â€¢	run research agent
	â€¢	export final JSON report if desired

Notes & configuration
	â€¢	By default the project uses SentenceTransformers (all-MiniLM-L6-v2) for embeddings (no external key).
	â€¢	Set OPENAI_API_KEY to use OpenAI to produce higher-quality summarizations (see .env.example).
	â€¢	Optionally set SERPAPI_API_KEY to use SerpAPI for broader web results. If not set, the app falls back to Wikipedia.


## ğŸ“¸ Screenshots

### Home Page
![Home Page](Screenshots/Homepage.png)

### Search-results Output
![Search Results](Screenshots/Searchresults.png)

### Final-report and traceability
![Report Output](Screenshots/Finalreport.png)
